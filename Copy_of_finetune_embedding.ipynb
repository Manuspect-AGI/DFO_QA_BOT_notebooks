{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28a8b793",
      "metadata": {
        "id": "28a8b793"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/finetuning/embeddings/finetune_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "551753b7-6cd2-4f81-aec0-da119e4705ad",
      "metadata": {
        "id": "551753b7-6cd2-4f81-aec0-da119e4705ad"
      },
      "source": [
        "# Finetune Embeddings\n",
        "\n",
        "In this notebook, we show users how to finetune their own embedding models.\n",
        "\n",
        "We go through three main sections:\n",
        "1. Preparing the data (our `generate_qa_embedding_pairs` function makes this easy)\n",
        "2. Finetuning the model (using our `SentenceTransformersFinetuneEngine`)\n",
        "3. Evaluating the model on a validation knowledge corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99afd542-fc47-44ac-aed0-b3684108dba5",
      "metadata": {
        "id": "99afd542-fc47-44ac-aed0-b3684108dba5"
      },
      "source": [
        "## Generate Corpus\n",
        "\n",
        "First, we create the corpus of text chunks by leveraging LlamaIndex to load some financial PDFs, and parsing/chunking into plain text chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e973679e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e973679e",
        "outputId": "b66dd4f1-08ba-4bb7-dbc4-350b61e5d1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.10/dist-packages (0.1.21)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (0.10.42)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.30.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: llama-index-embeddings-openai in /usr/local/lib/python3.10/dist-packages (0.1.10)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai) (0.10.42)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.30.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: llama-index-finetuning in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /usr/local/lib/python3.10/dist-packages (from llama-index-finetuning) (0.10.42)\n",
            "Requirement already satisfied: llama-index-embeddings-adapter<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-finetuning) (0.1.3)\n",
            "Requirement already satisfied: llama-index-llms-gradient<0.2.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-finetuning) (0.1.2)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-finetuning) (0.1.21)\n",
            "Requirement already satisfied: llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-finetuning) (0.1.7)\n",
            "Requirement already satisfied: sentence-transformers<3.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-finetuning) (2.7.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.30.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.14.1)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (2.3.0+cu121)\n",
            "Requirement already satisfied: gradientai<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (1.13.0)\n",
            "Requirement already satisfied: cohere<6.0.0,>=5.1.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (5.5.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (4.39.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.23.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.0.3)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.34.117)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.9.4)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.7.1)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.15.2)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.32.0.20240523)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (3.1.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (2.0.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.14.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (24.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (12.5.40)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.4.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.21.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.5.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.2.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.117 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.34.117)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-llms-openai\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9280d438-b6bd-4ccf-a730-7c8bb3ebdbeb",
      "metadata": {
        "id": "9280d438-b6bd-4ccf-a730-7c8bb3ebdbeb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.schema import MetadataMode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c42620",
      "metadata": {
        "id": "73c42620"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e11b0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8e11b0c",
        "outputId": "9fd70f60-1bc9-4460-df1c-3fb9d2552c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-01 08:09:00--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1880483 (1.8M) [application/octet-stream]\n",
            "Saving to: ‘data/10k/uber_2021.pdf’\n",
            "\n",
            "data/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-06-01 08:09:00 (25.5 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\n",
            "\n",
            "--2024-06-01 08:09:00--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1440303 (1.4M) [application/octet-stream]\n",
            "Saving to: ‘data/10k/lyft_2021.pdf’\n",
            "\n",
            "data/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-06-01 08:09:01 (19.3 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p 'data/10k/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf' -O 'data/10k/lyft_2021.pdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e890bc-557b-4d3c-bede-3e80dfeeee18",
      "metadata": {
        "id": "c5e890bc-557b-4d3c-bede-3e80dfeeee18"
      },
      "outputs": [],
      "source": [
        "TRAIN_FILES = [\"/content/data/10k/lyft_2021.pdf\"]\n",
        "VAL_FILES = [\"/content/data/10k/uber_2021.pdf\"]\n",
        "\n",
        "TRAIN_CORPUS_FPATH = \"./data/train_corpus.json\"\n",
        "VAL_CORPUS_FPATH = \"./data/val_corpus.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da871c1-9d58-467a-92fd-06ed3d94534b",
      "metadata": {
        "id": "1da871c1-9d58-467a-92fd-06ed3d94534b"
      },
      "outputs": [],
      "source": [
        "def load_corpus(files, verbose=False):\n",
        "    if verbose:\n",
        "        print(f\"Loading files {files}\")\n",
        "\n",
        "    reader = SimpleDirectoryReader(input_files=files)\n",
        "    docs = reader.load_data()\n",
        "    if verbose:\n",
        "        print(f\"Loaded {len(docs)} docs\")\n",
        "\n",
        "    parser = SentenceSplitter()\n",
        "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Parsed {len(nodes)} nodes\")\n",
        "\n",
        "    return nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pNURjlJztVsJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNURjlJztVsJ",
        "outputId": "2c0fef66-0660-4885-9800-de478f3d1c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "%pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YerlIH3mtUS3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YerlIH3mtUS3",
        "outputId": "3ae6937b-6ef9-4356-cdd7-3b6e670a81ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting text from /content/data/10k/lyft_2021.pdf\n",
            "Corpus created at ./data/train_corpus.json\n",
            "Extracting text from /content/data/10k/uber_2021.pdf\n",
            "Corpus created at ./data/val_corpus.json\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "import json\n",
        "import os\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        number_of_pages = len(reader.pages)\n",
        "        for page_num in range(number_of_pages):\n",
        "            page = reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def create_corpus(files, output_path, verbose=False):\n",
        "    corpus = {}\n",
        "    for file_path in files:\n",
        "        if verbose:\n",
        "            print(f\"Extracting text from {file_path}\")\n",
        "        text = extract_text_from_pdf(file_path)\n",
        "        corpus[os.path.basename(file_path)] = text\n",
        "    with open(output_path, 'w') as outfile:\n",
        "        json.dump(corpus, outfile)\n",
        "    if verbose:\n",
        "        print(f\"Corpus created at {output_path}\")\n",
        "\n",
        "# Define file paths\n",
        "TRAIN_FILES = [\"/content/data/10k/lyft_2021.pdf\"]\n",
        "VAL_FILES = [\"/content/data/10k/uber_2021.pdf\"]\n",
        "\n",
        "TRAIN_CORPUS_FPATH = \"./data/train_corpus.json\"\n",
        "VAL_CORPUS_FPATH = \"./data/val_corpus.json\"\n",
        "# Create corpora\n",
        "create_corpus(TRAIN_FILES, TRAIN_CORPUS_FPATH, verbose=True)\n",
        "create_corpus(VAL_FILES, VAL_CORPUS_FPATH, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pP_b0bNWw4sP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP_b0bNWw4sP",
        "outputId": "7ac2fdeb-49ae-4a67-9e69-824e79b67e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.10.42)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.2.6)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.12)\n",
            "Requirement already satisfied: llama-index-core==0.10.42 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.10.42)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.10)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.21)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.23)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (1.30.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.42->llama_index) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.2.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index) (0.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.42->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.42->llama_index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.42->llama_index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.42->llama_index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.42->llama_index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.42->llama_index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.42->llama_index) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.42->llama_index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.42->llama_index) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.42->llama_index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.42->llama_index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.42->llama_index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.42->llama_index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.42->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.42->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.42->llama_index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.42->llama_index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.42->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.42->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.42->llama_index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.42->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.42->llama_index) (3.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.42->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.42->llama_index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.42->llama_index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.42->llama_index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.42->llama_index) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.42->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.42->llama_index) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.42->llama_index) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install llama_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53056d8b-3b4c-4364-9b07-a375aa84330b",
      "metadata": {
        "id": "53056d8b-3b4c-4364-9b07-a375aa84330b"
      },
      "source": [
        "We do a very naive train/val split by having the Lyft corpus as the train dataset, and the Uber corpus as the val dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3651c77-d085-4fbc-bb34-61f143ad6674",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "421c4a9536d64a86b9f4fc4a405852d3",
            "e3b0c9183c494fdf951f149ba346cfc9",
            "5fd3a24a1a5847efa4b6d4e3703438e7",
            "7e7d4109b61b43029b17347a4614be7c",
            "060a7d4e642448a59eca4469f1bd139c",
            "615456d679d94a01801ca89ca9185b52",
            "61e4fd7fdc6941e88b4b8ab875887ec5",
            "fb1b50b6c6ff4c9a828d25190694470c",
            "066a6c6ea4ab4050a7073cbe5dd8de90",
            "0748a1c8fbfc4df783d3b30e697f85b0",
            "e73e95aeb7bf457eaf0d56efdcbbd95e",
            "502c9f964b0c4c94995075070de6a6db",
            "2ab4754f48214428afffe051f3569b74",
            "bdcce28d4aa3433ea577a31cbec483a0",
            "3e68ee725c184752873a37e24ed50fee",
            "d06b1472136b4d0490453fabf1480d7c",
            "82aaed23a8444dd99d6092927906bd5f",
            "f7f78b2baaf04c6ab4e4bd5724b7e23c",
            "6139a042977141138b40e6a9a79d30ce",
            "d565c08c21124ca1873cd11751f6b658",
            "79735512da6143f8b4c063ba77d85896",
            "c8e32daedb324a1794520547c970ba66"
          ]
        },
        "id": "d3651c77-d085-4fbc-bb34-61f143ad6674",
        "outputId": "1d3091a0-51c7-4343-fffe-322fd9e3b8d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files ['/content/data/10k/lyft_2021.pdf']\n",
            "Loaded 238 docs\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "421c4a9536d64a86b9f4fc4a405852d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/238 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed 344 nodes\n",
            "Loading files ['/content/data/10k/uber_2021.pdf']\n",
            "Loaded 307 docs\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "502c9f964b0c4c94995075070de6a6db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/307 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed 411 nodes\n"
          ]
        }
      ],
      "source": [
        "train_nodes = load_corpus(TRAIN_FILES, verbose=True)\n",
        "val_nodes = load_corpus(VAL_FILES, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4482c48-844b-448b-9552-3f38b455645c",
      "metadata": {
        "id": "b4482c48-844b-448b-9552-3f38b455645c"
      },
      "source": [
        "### Generate synthetic queries\n",
        "\n",
        "Now, we use an LLM (gpt-3.5-turbo) to generate questions using each text chunk in the corpus as context.\n",
        "\n",
        "Each pair of (generated question, text chunk used as context) becomes a datapoint in the finetuning dataset (either for training or evaluation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580334ce-ddaa-4cc0-8c3e-7294d11e4d2f",
      "metadata": {
        "id": "580334ce-ddaa-4cc0-8c3e-7294d11e4d2f"
      },
      "outputs": [],
      "source": [
        "from llama_index.finetuning import generate_qa_embedding_pairs\n",
        "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "666001e2",
      "metadata": {
        "id": "666001e2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_KEY = \"sk-proj-5MYyWsH9JRwufKt4xPsFT3BlbkFJxFLePUoh5IqPC7WWzgXt\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef43fe59-a29c-481b-b086-e98e55016d3e",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef43fe59-a29c-481b-b086-e98e55016d3e",
        "outputId": "5ac01c02-c711-4126-af54-7854373e1e85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344/344 [06:46<00:00,  1.18s/it]\n",
            "100%|██████████| 411/411 [08:44<00:00,  1.28s/it]\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "\n",
        "train_dataset = generate_qa_embedding_pairs(\n",
        "    llm=OpenAI(model=\"gpt-3.5-turbo\"), nodes=train_nodes\n",
        ")\n",
        "val_dataset = generate_qa_embedding_pairs(\n",
        "    llm=OpenAI(model=\"gpt-3.5-turbo\"), nodes=val_nodes\n",
        ")\n",
        "\n",
        "train_dataset.save_json(\"train_dataset.json\")\n",
        "val_dataset.save_json(\"val_dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743f163c-25df-4c18-9abe-05052b034d70",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "743f163c-25df-4c18-9abe-05052b034d70"
      },
      "outputs": [],
      "source": [
        "# [Optional] Load\n",
        "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
        "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62368cb8-a303-48b1-8429-5e3655abcc3b",
      "metadata": {
        "id": "62368cb8-a303-48b1-8429-5e3655abcc3b"
      },
      "source": [
        "## Run Embedding Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d08066-5f00-48f1-b12a-e80bc193d4c0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c1d08066-5f00-48f1-b12a-e80bc193d4c0"
      },
      "outputs": [],
      "source": [
        "from llama_index.finetuning import SentenceTransformersFinetuneEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26625ab5-ddc9-4dbd-9936-39b69c6a7cdc",
      "metadata": {
        "id": "26625ab5-ddc9-4dbd-9936-39b69c6a7cdc"
      },
      "outputs": [],
      "source": [
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"BAAI/bge-small-en\",\n",
        "    model_output_path=\"test_model\",\n",
        "    val_dataset=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ad99e6-dd9d-485a-86e9-1845cf51802b",
      "metadata": {
        "id": "28ad99e6-dd9d-485a-86e9-1845cf51802b"
      },
      "outputs": [],
      "source": [
        "finetune_engine.finetune()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "467a2ba2-e7e6-4025-8887-cac6e7ecb493",
      "metadata": {
        "id": "467a2ba2-e7e6-4025-8887-cac6e7ecb493"
      },
      "outputs": [],
      "source": [
        "embed_model = finetune_engine.get_finetuned_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d16ec01-c29d-4742-aa3c-5ded6ae7c5a7",
      "metadata": {
        "id": "5d16ec01-c29d-4742-aa3c-5ded6ae7c5a7",
        "outputId": "b9175da5-3a7e-4b3f-b2f9-601ef911b0dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceEmbedding(model_name='test_model', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x2cc3d5cd0>, tokenizer_name='test_model', max_length=512, pooling=<Pooling.CLS: 'cls'>, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "828dd6fe-9a8a-419b-8663-56d81ce73774",
      "metadata": {
        "id": "828dd6fe-9a8a-419b-8663-56d81ce73774"
      },
      "source": [
        "## Evaluate Finetuned Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a66b83-4cbb-4374-a632-0f1bb2b785ab",
      "metadata": {
        "id": "f4a66b83-4cbb-4374-a632-0f1bb2b785ab"
      },
      "source": [
        "In this section, we evaluate 3 different embedding models:\n",
        "1. proprietary OpenAI embedding,\n",
        "2. open source `BAAI/bge-small-en`, and\n",
        "3. our finetuned embedding model.\n",
        "\n",
        "We consider 2 evaluation approaches:\n",
        "1. a simple custom **hit rate** metric\n",
        "2. using `InformationRetrievalEvaluator` from sentence_transformers\n",
        "\n",
        "We show that finetuning on synthetic (LLM-generated) dataset significantly improve upon an opensource embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d5176f-1f21-4bcb-adf5-da1c4cccb8d3",
      "metadata": {
        "id": "57d5176f-1f21-4bcb-adf5-da1c4cccb8d3"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.schema import TextNode\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dda4c2b8-1ad8-420c-83d2-b88e0519895d",
      "metadata": {
        "id": "dda4c2b8-1ad8-420c-83d2-b88e0519895d"
      },
      "source": [
        "### Define eval function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398c24d3-3d72-4ce8-94a4-2da9c1b2605c",
      "metadata": {
        "id": "398c24d3-3d72-4ce8-94a4-2da9c1b2605c"
      },
      "source": [
        "**Option 1**: We use a simple **hit rate** metric for evaluation:\n",
        "* for each (query, relevant_doc) pair,\n",
        "* we retrieve top-k documents with the query,  and\n",
        "* it's a **hit** if the results contain the relevant_doc.\n",
        "\n",
        "This approach is very simple and intuitive, and we can apply it to both the proprietary OpenAI embedding as well as our open source and fine-tuned embedding models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89401d3-a157-4f96-86d4-212e631a54bc",
      "metadata": {
        "id": "b89401d3-a157-4f96-86d4-212e631a54bc"
      },
      "outputs": [],
      "source": [
        "def evaluate(\n",
        "    dataset,\n",
        "    embed_model,\n",
        "    top_k=5,\n",
        "    verbose=False,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
        "    index = VectorStoreIndex(\n",
        "        nodes, embed_model=embed_model, show_progress=True\n",
        "    )\n",
        "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
        "\n",
        "    eval_results = []\n",
        "    for query_id, query in tqdm(queries.items()):\n",
        "        retrieved_nodes = retriever.retrieve(query)\n",
        "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
        "        expected_id = relevant_docs[query_id][0]\n",
        "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
        "\n",
        "        eval_result = {\n",
        "            \"is_hit\": is_hit,\n",
        "            \"retrieved\": retrieved_ids,\n",
        "            \"expected\": expected_id,\n",
        "            \"query\": query_id,\n",
        "        }\n",
        "        eval_results.append(eval_result)\n",
        "    return eval_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb16251-bb45-4de0-b65a-e15aa76e0f1e",
      "metadata": {
        "id": "7eb16251-bb45-4de0-b65a-e15aa76e0f1e"
      },
      "source": [
        "**Option 2**: We use the `InformationRetrievalEvaluator` from sentence_transformers.\n",
        "\n",
        "This provides a more comprehensive suite of metrics, but we can only run it against the sentencetransformers compatible models (open source and our finetuned model, *not* the OpenAI embedding model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e89702-ea35-4c22-99c7-f89a5428ef95",
      "metadata": {
        "id": "88e89702-ea35-4c22-99c7-f89a5428ef95"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def evaluate_st(\n",
        "    dataset,\n",
        "    model_id,\n",
        "    name,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    evaluator = InformationRetrievalEvaluator(\n",
        "        queries, corpus, relevant_docs, name=name\n",
        "    )\n",
        "    model = SentenceTransformer(model_id)\n",
        "    output_path = \"results/\"\n",
        "    Path(output_path).mkdir(exist_ok=True, parents=True)\n",
        "    return evaluator(model, output_path=output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2d33dd-c39f-4c05-8adc-65db12163c88",
      "metadata": {
        "id": "af2d33dd-c39f-4c05-8adc-65db12163c88"
      },
      "source": [
        "### Run Evals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c630aa25-2395-4a8b-83cf-2885fbc862f4",
      "metadata": {
        "id": "c630aa25-2395-4a8b-83cf-2885fbc862f4"
      },
      "source": [
        "#### OpenAI\n",
        "\n",
        "Note: this might take a few minutes to run since we have to embed the corpus and queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a0784f-415e-4d3a-8c88-757b28b9e5df",
      "metadata": {
        "id": "61a0784f-415e-4d3a-8c88-757b28b9e5df"
      },
      "outputs": [],
      "source": [
        "ada = OpenAIEmbedding()\n",
        "ada_val_results = evaluate(val_dataset, ada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc73212-fc53-48c1-b347-f5ee3a29ae82",
      "metadata": {
        "id": "ccc73212-fc53-48c1-b347-f5ee3a29ae82"
      },
      "outputs": [],
      "source": [
        "df_ada = pd.DataFrame(ada_val_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25eb61bb-c287-40fe-b3c7-bbfc2d2b1b94",
      "metadata": {
        "id": "25eb61bb-c287-40fe-b3c7-bbfc2d2b1b94",
        "outputId": "ab33d0f9-e423-4199-a8aa-9f46ddefb0b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8779904306220095"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hit_rate_ada = df_ada[\"is_hit\"].mean()\n",
        "hit_rate_ada"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1bd6c62-65a8-4f72-a67c-d0d62c92d7d1",
      "metadata": {
        "id": "a1bd6c62-65a8-4f72-a67c-d0d62c92d7d1"
      },
      "source": [
        "### BAAI/bge-small-en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24454aeb-9e3e-4954-ab70-647102ed7f82",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6e9c5f0555f641caa3a5a5d11cb87583",
            "1fe9a221f8984c818727771d12dfef71",
            "619c9cae8bf24987a4d3453aa69d24b9",
            "082cfe7c9f3646948886c90f0e1f4258",
            "3ff8d7a739fc425abf24076c47c0ab29",
            "0a5344851cb14ed8a5f788cbd74a90d8",
            "eaa8bdab99244058b1df3eae12a79b20",
            "e21b1a35d6c54644be124c357852fedf",
            "927efec699ea4c929da7214eb51fc64c",
            "1c8a00d15090422181a9749e0638e883",
            "3845bc276c88482ba0e2f2fbe317dd78",
            "7ceca7b6507e42b1b3da10711b37b7ab",
            "21170e7cf0f9485a9095807a6225aa12",
            "3712232b7e064486879945c4d4ac5535",
            "ba1f47ec020447c59d008493b31e0a57"
          ]
        },
        "id": "24454aeb-9e3e-4954-ab70-647102ed7f82",
        "outputId": "6326e0a9-fe60-4ff2-9525-53482e703557"
      },
      "outputs": [
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.011851787567138672,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)ab102/.gitattributes",
              "rate": null,
              "total": 1519,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e9c5f0555f641caa3a5a5d11cb87583",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ab102/.gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.009984016418457031,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)_Pooling/config.json",
              "rate": null,
              "total": 190,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fe9a221f8984c818727771d12dfef71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.006695985794067383,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)2d2d7ab102/README.md",
              "rate": null,
              "total": 78855,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "619c9cae8bf24987a4d3453aa69d24b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)2d2d7ab102/README.md:   0%|          | 0.00/78.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.008507966995239258,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)2d7ab102/config.json",
              "rate": null,
              "total": 684,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "082cfe7c9f3646948886c90f0e1f4258",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)2d7ab102/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.011520147323608398,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)ce_transformers.json",
              "rate": null,
              "total": 124,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ff8d7a739fc425abf24076c47c0ab29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.010421991348266602,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading model.safetensors",
              "rate": null,
              "total": 133466304,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a5344851cb14ed8a5f788cbd74a90d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.010251045227050781,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading pytorch_model.bin",
              "rate": null,
              "total": 133508397,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaa8bdab99244058b1df3eae12a79b20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.012272834777832031,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)nce_bert_config.json",
              "rate": null,
              "total": 52,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e21b1a35d6c54644be124c357852fedf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0071942806243896484,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)cial_tokens_map.json",
              "rate": null,
              "total": 125,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "927efec699ea4c929da7214eb51fc64c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.010439872741699219,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)ab102/tokenizer.json",
              "rate": null,
              "total": 711396,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c8a00d15090422181a9749e0638e883",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ab102/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.005940914154052734,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)okenizer_config.json",
              "rate": null,
              "total": 366,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3845bc276c88482ba0e2f2fbe317dd78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.00838780403137207,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)2d2d7ab102/vocab.txt",
              "rate": null,
              "total": 231508,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ceca7b6507e42b1b3da10711b37b7ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)2d2d7ab102/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.007328987121582031,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Downloading (…)d7ab102/modules.json",
              "rate": null,
              "total": 229,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21170e7cf0f9485a9095807a6225aa12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)d7ab102/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.001703023910522461,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "Generating embeddings",
              "rate": null,
              "total": 418,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3712232b7e064486879945c4d4ac5535",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/418 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0017049312591552734,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": 28,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 836,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba1f47ec020447c59d008493b31e0a57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/836 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bge = \"local:BAAI/bge-small-en\"\n",
        "bge_val_results = evaluate(val_dataset, bge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da27e48-1c90-4994-aac4-96b5b1638647",
      "metadata": {
        "id": "2da27e48-1c90-4994-aac4-96b5b1638647"
      },
      "outputs": [],
      "source": [
        "df_bge = pd.DataFrame(bge_val_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddc4fe0-b240-4c15-9b2d-a4c79f9aaac2",
      "metadata": {
        "id": "3ddc4fe0-b240-4c15-9b2d-a4c79f9aaac2",
        "outputId": "9fd23b80-e103-462a-d116-f8ae699b170e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7930622009569378"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hit_rate_bge = df_bge[\"is_hit\"].mean()\n",
        "hit_rate_bge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c16df14-6564-41ec-8816-348675bb0fd4",
      "metadata": {
        "id": "2c16df14-6564-41ec-8816-348675bb0fd4",
        "outputId": "a30b32ce-ffaf-4ca7-a63f-a2fe8c4b947c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'results/Information-Retrieval_evaluation_bge_results.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_st\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBAAI/bge-small-en\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[49], line 15\u001b[0m, in \u001b[0;36mevaluate_st\u001b[0;34m(dataset, model_id, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m InformationRetrievalEvaluator(queries, corpus, relevant_docs, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(model_id)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/sentence_transformers/evaluation/InformationRetrievalEvaluator.py:104\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_file)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(csv_path):\n\u001b[0;32m--> 104\u001b[0m     fOut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     fOut\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_headers))\n\u001b[1;32m    106\u001b[0m     fOut\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/Information-Retrieval_evaluation_bge_results.csv'"
          ]
        }
      ],
      "source": [
        "evaluate_st(val_dataset, \"BAAI/bge-small-en\", name=\"bge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd87550-f547-4b8b-b21a-f72b355e2cd7",
      "metadata": {
        "id": "1fd87550-f547-4b8b-b21a-f72b355e2cd7"
      },
      "source": [
        "### Finetuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "402dd440-1934-4778-8ff5-28e15cf1f2d3",
      "metadata": {
        "id": "402dd440-1934-4778-8ff5-28e15cf1f2d3"
      },
      "outputs": [],
      "source": [
        "finetuned = \"local:test_model\"\n",
        "val_results_finetuned = evaluate(val_dataset, finetuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffd24643-17cb-4773-a535-77f3f8fa2d48",
      "metadata": {
        "id": "ffd24643-17cb-4773-a535-77f3f8fa2d48"
      },
      "outputs": [],
      "source": [
        "df_finetuned = pd.DataFrame(val_results_finetuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1dccd1-bbd4-427f-a520-b1011643d83b",
      "metadata": {
        "id": "ec1dccd1-bbd4-427f-a520-b1011643d83b"
      },
      "outputs": [],
      "source": [
        "hit_rate_finetuned = df_finetuned[\"is_hit\"].mean()\n",
        "hit_rate_finetuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8dd38e-f13d-43e1-9802-cc94b854526b",
      "metadata": {
        "id": "9d8dd38e-f13d-43e1-9802-cc94b854526b"
      },
      "outputs": [],
      "source": [
        "evaluate_st(val_dataset, \"test_model\", name=\"finetuned\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc290bc-5cc3-4ee4-b8ab-e68371441643",
      "metadata": {
        "id": "fbc290bc-5cc3-4ee4-b8ab-e68371441643"
      },
      "source": [
        "### Summary of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f906a11-6a95-4f10-9069-140bf5a56246",
      "metadata": {
        "id": "6f906a11-6a95-4f10-9069-140bf5a56246"
      },
      "source": [
        "#### Hit rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705fbe3c-2843-4bab-bb5c-16027fc5564b",
      "metadata": {
        "id": "705fbe3c-2843-4bab-bb5c-16027fc5564b"
      },
      "outputs": [],
      "source": [
        "df_ada[\"model\"] = \"ada\"\n",
        "df_bge[\"model\"] = \"bge\"\n",
        "df_finetuned[\"model\"] = \"fine_tuned\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebc363c-cd07-4dab-916e-1618d16d1254",
      "metadata": {
        "id": "bebc363c-cd07-4dab-916e-1618d16d1254"
      },
      "source": [
        "We can see that fine-tuning our small open-source embedding model drastically improve its retrieval quality (even approaching the quality of the proprietary OpenAI embedding)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f38b4b-1b40-42da-a054-ea9593d3e602",
      "metadata": {
        "id": "57f38b4b-1b40-42da-a054-ea9593d3e602"
      },
      "outputs": [],
      "source": [
        "df_all = pd.concat([df_ada, df_bge, df_finetuned])\n",
        "df_all.groupby(\"model\").mean(\"is_hit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08094d07-2c0a-44ca-ad2f-8d8bf1387ed9",
      "metadata": {
        "id": "08094d07-2c0a-44ca-ad2f-8d8bf1387ed9"
      },
      "source": [
        "#### InformationRetrievalEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d0444e-a824-42d6-9ddb-4da7179902bc",
      "metadata": {
        "id": "27d0444e-a824-42d6-9ddb-4da7179902bc"
      },
      "outputs": [],
      "source": [
        "df_st_bge = pd.read_csv(\n",
        "    \"results/Information-Retrieval_evaluation_bge_results.csv\"\n",
        ")\n",
        "df_st_finetuned = pd.read_csv(\n",
        "    \"results/Information-Retrieval_evaluation_finetuned_results.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0903ed3-df05-4d98-8b0a-6f352c681735",
      "metadata": {
        "id": "c0903ed3-df05-4d98-8b0a-6f352c681735"
      },
      "source": [
        "We can see that embedding finetuning improves metrics consistently across the suite of eval metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ec1c46-5aa0-4f8a-a0c5-2553e08cceb1",
      "metadata": {
        "id": "81ec1c46-5aa0-4f8a-a0c5-2553e08cceb1"
      },
      "outputs": [],
      "source": [
        "df_st_bge[\"model\"] = \"bge\"\n",
        "df_st_finetuned[\"model\"] = \"fine_tuned\"\n",
        "df_st_all = pd.concat([df_st_bge, df_st_finetuned])\n",
        "df_st_all = df_st_all.set_index(\"model\")\n",
        "df_st_all"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "060a7d4e642448a59eca4469f1bd139c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066a6c6ea4ab4050a7073cbe5dd8de90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0748a1c8fbfc4df783d3b30e697f85b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab4754f48214428afffe051f3569b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82aaed23a8444dd99d6092927906bd5f",
            "placeholder": "​",
            "style": "IPY_MODEL_f7f78b2baaf04c6ab4e4bd5724b7e23c",
            "value": "Parsing nodes: 100%"
          }
        },
        "3e68ee725c184752873a37e24ed50fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79735512da6143f8b4c063ba77d85896",
            "placeholder": "​",
            "style": "IPY_MODEL_c8e32daedb324a1794520547c970ba66",
            "value": " 307/307 [00:01&lt;00:00, 464.61it/s]"
          }
        },
        "421c4a9536d64a86b9f4fc4a405852d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3b0c9183c494fdf951f149ba346cfc9",
              "IPY_MODEL_5fd3a24a1a5847efa4b6d4e3703438e7",
              "IPY_MODEL_7e7d4109b61b43029b17347a4614be7c"
            ],
            "layout": "IPY_MODEL_060a7d4e642448a59eca4469f1bd139c"
          }
        },
        "502c9f964b0c4c94995075070de6a6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ab4754f48214428afffe051f3569b74",
              "IPY_MODEL_bdcce28d4aa3433ea577a31cbec483a0",
              "IPY_MODEL_3e68ee725c184752873a37e24ed50fee"
            ],
            "layout": "IPY_MODEL_d06b1472136b4d0490453fabf1480d7c"
          }
        },
        "5fd3a24a1a5847efa4b6d4e3703438e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1b50b6c6ff4c9a828d25190694470c",
            "max": 238,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_066a6c6ea4ab4050a7073cbe5dd8de90",
            "value": 238
          }
        },
        "6139a042977141138b40e6a9a79d30ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615456d679d94a01801ca89ca9185b52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e4fd7fdc6941e88b4b8ab875887ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79735512da6143f8b4c063ba77d85896": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7d4109b61b43029b17347a4614be7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0748a1c8fbfc4df783d3b30e697f85b0",
            "placeholder": "​",
            "style": "IPY_MODEL_e73e95aeb7bf457eaf0d56efdcbbd95e",
            "value": " 238/238 [00:01&lt;00:00, 235.67it/s]"
          }
        },
        "82aaed23a8444dd99d6092927906bd5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdcce28d4aa3433ea577a31cbec483a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6139a042977141138b40e6a9a79d30ce",
            "max": 307,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d565c08c21124ca1873cd11751f6b658",
            "value": 307
          }
        },
        "c8e32daedb324a1794520547c970ba66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06b1472136b4d0490453fabf1480d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d565c08c21124ca1873cd11751f6b658": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3b0c9183c494fdf951f149ba346cfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_615456d679d94a01801ca89ca9185b52",
            "placeholder": "​",
            "style": "IPY_MODEL_61e4fd7fdc6941e88b4b8ab875887ec5",
            "value": "Parsing nodes: 100%"
          }
        },
        "e73e95aeb7bf457eaf0d56efdcbbd95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7f78b2baaf04c6ab4e4bd5724b7e23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb1b50b6c6ff4c9a828d25190694470c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}